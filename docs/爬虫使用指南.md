# 爬虫使用指南

本文档介绍如何运行爬虫、处理数据以及查询爬虫数据的方法。

## 1. 爬虫概述

系统目前集成了三种爬虫：

- **新闻爬虫 (news)**: 爬取主流新闻网站（新华网、人民网、中国日报）的内容
- **政府网站爬虫 (government)**: 爬取政府官方网站（中国政府网、国家卫健委）的信息
- **微博爬虫 (weibo)**: 爬取微博热搜和特定关键词的微博内容

## 2. 运行爬虫

### 2.1 启动单个爬虫

```bash
# 运行微博爬虫
python app/run_crawler.py run weibo

# 运行新闻爬虫
python app/run_crawler.py run news

# 运行政府网站爬虫
python app/run_crawler.py run government
```

### 2.2 启动所有爬虫

```bash
python app/run_crawler.py run
```

## 3. 处理爬虫数据

爬虫抓取到的原始数据需要经过处理才能更好地被利用：

```bash
python app/run_crawler.py process
```

数据处理包括：
- 内容清洗（去除HTML标签、广告等）
- 摘要生成
- 标签提取
- 关键词匹配度计算
- 推荐级别评估

## 4. 查询爬虫数据

### 4.1 查看最新数据

```bash
# 查看最新新闻数据
python app/run_crawler.py query news

# 查看最新谣言数据
python app/run_crawler.py query rumor

# 查看最新社交媒体数据
python app/run_crawler.py query social
```

### 4.2 使用过滤条件

```bash
# 查看带关键词的新闻数据
python app/run_crawler.py query news -k 疫情

# 查看最近7天的谣言数据
python app/run_crawler.py query rumor -d 7

# 查看最近30天带关键词的社交媒体数据，返回20条
python app/run_crawler.py query social -d 30 -k 辟谣 -l 20
```

### 4.3 可用参数

- `-l, --limit`: 返回数据条数，默认为10条
- `-d, --days`: 查询最近几天的数据
- `-k, --keywords`: 关键词过滤

## 5. 查看数据统计

```bash
python app/run_crawler.py stats
```

显示的统计信息包括：
- 各类型数据总数
- 最近爬取时间

## 6. 参考

### 6.1 命令帮助

```bash
# 显示主命令帮助
python app/run_crawler.py --help

# 显示查询命令帮助
python app/run_crawler.py query --help
```

### 6.2 数据模型

爬虫数据存储在以下数据表中：
- `news_data`: 新闻数据
- `rumor_data`: 谣言数据
- `social_media_data`: 社交媒体数据
- `data_process_log`: 数据处理日志

### 6.3 注意事项

1. 微博爬虫需要有效的Cookie才能正常工作，Cookie配置在系统设置中
2. 爬虫遵循robots.txt规则，默认下载延迟为2秒
3. 爬虫会自动根据关键词过滤与辟谣无关的内容
4. 数据处理可能需要较长时间，请耐心等待
5. 爬虫数据存储在数据库中，可通过系统API或本工具查询 