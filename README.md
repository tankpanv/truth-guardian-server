## 真相卫士系统 - 技术文档

真相卫士系统是一个集信息采集、分析、发布于一体的辟谣平台，利用先进的爬虫技术和数据处理算法，帮助用户识别和澄清互联网上的虚假信息。
# 向所有用户推送
python send_message.py --all-users --now

#python send_message.py --username user1 --now --limit 5
# python send_message.py  --now
# 向指定用户推送
#python send_message.py --username user1 --now
# 清空数据，慎用
# python scripts/clean_database.py --tables all --confirm

# 向订阅用户推送（默认）
#python send_message.py --now

# 启动定时推送给指定用户
#python send_message.py --username user1

# 启动定时推送给所有用户
#python send_message.py --all-users
### 技术栈

#### 后端框架与库
- **Flask**: 轻量级Python Web框架，负责API接口和应用服务
- **SQLAlchemy**: ORM框架，处理数据库操作
- **Flask-JWT-Extended**: 实现JWT身份验证机制
- **Flask-Migrate**: 处理数据库版本迁移
- **Flask-Caching**: 实现API响应缓存
- **Scrapy**: 强大的爬虫框架，用于数据采集
- **BeautifulSoup4**: HTML解析库，辅助网页内容提取
- **Jieba**: 中文分词库，用于文本分析和关键词提取

#### 数据存储
- **MySQL/PostgreSQL**: 关系型数据库，存储结构化数据
- **对象存储服务**: 支持多种对象存储(阿里云OSS、腾讯COS、七牛云)，用于存储媒体文件

#### AI和自然语言处理
- **LLM集成**: 支持OpenAI、DeepSeek、通义千问等大语言模型
- **Coze平台集成**: 特定API接口用于辟谣机器人功能
- **关键词匹配算法**: 自定义算法用于内容相关性分析

#### 前端技术
- **现代HTML/CSS/JavaScript**: 构建用户界面
- **响应式设计**: 适配不同设备屏幕大小
- **Fetch API**: 处理前后端通信

### 核心功能模块

#### 1. 数据采集系统

##### 爬虫管道架构
真相卫士系统使用了高度定制化的Scrapy爬虫框架进行数据采集，主要包括：

- **多种专用爬虫**:
  - `NewsSpider`: 采集主流新闻网站信息
  - `GovSpider`: 采集政府官方网站权威发布
  - `WeiboSpider`: 采集社交媒体平台相关讨论

- **三层级管道处理**:
  - `DataCleanPipeline`: 数据清洗，去除HTML标签和广告内容
  - `DuplicateFilterPipeline`: 基于内存和数据库的双重去重机制
  - `DatabaseStoragePipeline`: 智能判断数据更新或新建

- **辅助工具类**:
  - `ScraperUtils`: 提供URL处理、文本提取、日期解析等通用功能
  - `BaseSpider`: 基础爬虫类，提供ID生成、重复检测等基础功能

##### 爬虫管理器
`CrawlerManager`类实现了爬虫任务的统一调度和管理：
- 定时任务调度（基于`schedule`库）
- 并发控制和资源管理
- 多进程爬取与任务监控

#### 2. 数据处理系统

- **数据清洗**: 文本标准化、HTML标签移除、特殊字符处理
- **去重算法**: 使用SHA256哈希和多字段组合指纹
- **分词与标签**: 基于`jieba`的中文分词和关键词提取
- **敏感内容过滤**: 广告内容自动识别与移除
- **内容评分系统**: 基于多维度指标的内容价值评估

#### 3. API接口层

- **认证系统**: JWT令牌认证，支持令牌刷新和权限控制
- **用户管理**: 用户注册、登录、信息修改、角色管理
- **内容接口**: 新闻、谣言、社交媒体数据的CRUD操作
- **辟谣接口**: 辟谣文章创建、发布、管理
- **AI对话接口**: 支持多种AI模型的对话能力

#### 4. AI辟谣机器人

- **多种LLM集成**: 支持集成多种大语言模型
- **Coze平台定制**: 专门针对辟谣场景优化的AI工作流
- **上下文管理**: 保持对话一致性和连贯性
- **知识库增强**: 结合专业辟谣知识库提高回答准确性

#### 5. 数据可视化和用户界面

- **响应式设计**: 支持桌面和移动设备
- **实时数据展示**: 动态更新的数据展示界面
- **用户交互优化**: 简洁直观的操作流程
- **搜索与过滤**: 高效的内容检索机制

### 系统架构

```
+------------------+     +-------------------+     +------------------+
|                  |     |                   |     |                  |
|  数据采集层      |---->|  数据处理层       |---->|  存储层          |
|  (Scrapy爬虫)    |     |  (清洗/去重/分析) |     |  (MySQL/OSS)     |
|                  |     |                   |     |                  |
+------------------+     +-------------------+     +------------------+
                                                           |
                                                           v
+------------------+     +-------------------+     +------------------+
|                  |     |                   |     |                  |
|  AI辟谣机器人    |<--->|  API服务层        |<----|  业务逻辑层      |
|  (LLM/Coze)      |     |  (Flask REST API) |     |  (Controllers)   |
|                  |     |                   |     |                  |
+------------------+     +-------------------+     +------------------+
                                   |
                                   v
                          +------------------+
                          |                  |
                          |  前端展示层      |
                          |  (响应式Web)     |
                          |                  |
                          +------------------+
```

### 部署与扩展

- **容器化支持**: 提供Docker配置，便于容器化部署
- **环境变量配置**: 通过`.env`文件灵活配置系统参数
- **模块化设计**: 各功能模块松耦合，便于单独扩展和维护
- **日志系统**: 完善的日志记录，支持多级别和轮转
- **错误处理**: 全面的异常捕获和处理机制

### 安全机制

- **API认证**: 基于JWT的API访问认证
- **防注入攻击**: 参数验证和SQL注入防护
- **跨域保护**: 合理配置的CORS策略
- **速率限制**: API访问频率控制
- **敏感信息保护**: 密码哈希存储和敏感配置隔离

## 爬虫管道系统

真相卫士系统使用Scrapy进行数据采集，爬虫管道系统是数据采集的重要组成部分，负责数据的清洗、去重和存储。

### 管道流程

1. **DataCleanPipeline**: 数据清洗管道
   - 清除HTML标签、多余空白字符、特殊字符等
   - 过滤广告内容
   - 检查数据完整性，确保标题和内容不为空

2. **DuplicateFilterPipeline**: 重复数据过滤管道
   - 使用哈希算法生成内容指纹
   - 基于内存和数据库进行双重去重
   - 防止数据库中出现重复条目

3. **DatabaseStoragePipeline**: 数据库存储管道
   - 将处理后的数据存储到对应的数据表
   - 支持新闻、谣言和社交媒体三种数据类型
   - 可智能判断是更新已有记录还是创建新记录

### 爬虫工具类

项目还包含一系列辅助工具，帮助爬虫更高效地完成任务：

- **ScraperUtils**: 提供URL清理、文本提取、日期解析等通用功能
- **BaseSpider**: 基础爬虫类，提供ID生成、关键词匹配等共享功能

### 爬虫类型

系统目前支持以下类型的爬虫：

- **NewsSpider**: 新闻网站爬虫，负责采集主流新闻网站的文章
- **GovSpider**: 政府网站爬虫，负责采集官方发布的权威信息
- **WeiboSpider**: 微博爬虫，负责采集社交媒体上的相关讨论

### 配置和运行

爬虫配置在`app/scraper/settings.py`文件中，包括:

```python
# 项目管道配置
ITEM_PIPELINES = {
    'app.scraper.pipelines.data_clean.DataCleanPipeline': 300,
    'app.scraper.pipelines.duplicate_filter.DuplicateFilterPipeline': 500,
    'app.scraper.pipelines.db_storage.DatabaseStoragePipeline': 800,
}

# 数据来源配置
TRUTH_GUARDIAN_SETTINGS = {
    'SOURCES': {
        'news': [...],  # 新闻网站列表
        'government': [...],  # 政府网站列表
        'rumor': [...],  # 辟谣平台列表
        'social': {...}  # 社交媒体配置
    },
    'KEYWORDS': [...],  # 关键词列表
    'CRAWL_INTERVAL': 2  # 爬取间隔(小时)
}
```

爬虫管理器(`app/scraper/crawler.py`)提供了统一的接口来启动和管理爬虫任务。 